{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Lesson 14 - Latent Variables and Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Activity: Twitter Lab\n",
    "In this exercise, we will compare some of the classical NLP tools from the last class with these more modern latent variable techniques.  We will do this by comparing information extraction on Twitter using two different methods.\n",
    "\n",
    "There is a pre-existing file of captured tweets you can use.  It is located in the datasets folder of the class repo. \n",
    "\n",
    "The sample `captured-tweets.txt` dataset in the repo was generated by collecting ~5000 tweets from the TwitterAPI using the keywords:\n",
    "- `Google`\n",
    "- `Microsoft`\n",
    "- `Goldman Sachs`\n",
    "- `Citigroup`\n",
    "- `Tesla`\n",
    "- `Verizon`\n",
    "- `Syria`\n",
    "- `Iran`\n",
    "- `Israel`\n",
    "- `Iraq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "nlp_toolkit = spacy.load('en')\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the tweet data\n",
    "filename = '../dataset/captured-tweets.txt'\n",
    "tweets = []\n",
    "for tweet in codecs.open(filename, 'r', encoding=\"utf-8\"):\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for nlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'GPE', u'London')\n",
      "(u'GPE', u'the United Kingdom')\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_toolkit(u'London is a big city in the United Kingdom.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)\n",
    "    # GPE London\n",
    "    # GPE United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` and identify if it mentions a company named 'Google'. Remember, `spacy` can find entities and codes them as `ORG` if they are a company. Look at the slides for class 13 if you need a hint.\n",
    "\n",
    "### Bonus (1b)\n",
    "\n",
    "Parameterise the company name so that the function works for any company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_company(parsed):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == \"Google\" and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 1b\n",
    "\n",
    "def mentions_company(parsed, company='Google'):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == company and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` \n",
    "and return the verbs of the sentence (preferably lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    for el in parsed:\n",
    "        if el.pos == spacy.parts_of_speech.VERB:\n",
    "            actions.append(el.text)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d\n",
    "For each tweet, parse it using spacy and print it out if the tweet has 'release' or 'announce' as a verb. You'll need to use your `mentions_company` and `get_actions` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft joins Google and Facebook with warnings to users about government spying https://t.co/tXjvgeHFOu https://t.co/TW7aJb37q9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_company(parsed, 'Google'):\n",
    "        actions = get_actions(parsed)        \n",
    "        if 'spying' in actions or 'announce' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'joins', u'spying']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @business: Where Amazon, Microsoft, Google, IBM and DigitalOcean are building data centers https://t.co/VX047Jm9tq https://t.co/opTaZzO7…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_company(parsed, 'Google'):\n",
    "        actions = get_actions(parsed)\n",
    "        if 'release' in actions or 'announce' in actions or 'building' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1e\n",
    "Write a function that identifies countries - HINT: the entity label for countries is GPE (or GeoPolitical Entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_country(parsed, country):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == country and entity.label_ == 'GPE':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1f\n",
    "\n",
    "Re-run (d) to find country tweets that discuss 'Iran' announcing or releasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont…\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/TRshnC6sVU\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/SlvcQtk3vE\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont…\n",
      "\n",
      "Hhmmm. Iran claiming to have 'warned Nigeria' to release detained Shiite leader.... @afalli\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "\n",
    "    if mentions_country(parsed, 'Iran'):\n",
    "        actions = get_actions(parsed)\n",
    "        if 'release' in actions or 'announce' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Build a word2vec model of the tweets we have collected using gensim.\n",
    "First take the collection of tweets and tokenize them using spacy.\n",
    "\n",
    "### Exercise 2a:\n",
    "* Think about how this should be done. \n",
    "* Should you only use upper-case or lower-case? \n",
    "* Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                for x in nlp_toolkit(t)] for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I made a(n) Small Tourmaline in Paradise Island! https://t.co/cAoW1b6DRc #Gameinsight #Androidgames #Android\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'I',\n",
       "  u'make',\n",
       "  u'a(n',\n",
       "  u')',\n",
       "  u'Small',\n",
       "  u'Tourmaline',\n",
       "  u'in',\n",
       "  u'Paradise',\n",
       "  u'Island',\n",
       "  u'!',\n",
       "  u'https://t.co/cAoW1b6DRc',\n",
       "  u'#',\n",
       "  u'Gameinsight',\n",
       "  u'#',\n",
       "  u'Androidgames',\n",
       "  u'#',\n",
       "  u'Android',\n",
       "  u'\\n']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_split[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "Build a word2vec model.\n",
    "Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c:\n",
    "Test your word2vec model with a few similarity functions. \n",
    "* Find words similar to 'tweet'.\n",
    "* Find words similar to 'rank'.\n",
    "* Find words similar to 'Google'.\n",
    "* Find words similar to 'Syria'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'us', 0.9996129274368286),\n",
       " (u'call', 0.999569296836853),\n",
       " (u'Your', 0.9995595812797546),\n",
       " (u'than', 0.9995377063751221),\n",
       " (u'10', 0.9995316863059998),\n",
       " (u'--', 0.9995256662368774),\n",
       " (u'at', 0.99952232837677),\n",
       " (u'ne', 0.9995107650756836),\n",
       " (u'set', 0.9995098114013672),\n",
       " (u'people', 0.9995038509368896)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['tweet'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Times', 0.9908788800239563),\n",
       " (u'1,100', 0.9908362030982971),\n",
       " (u'100', 0.9907811284065247),\n",
       " (u'Non', 0.9906907081604004),\n",
       " (u'York', 0.9905609488487244),\n",
       " (u'6P', 0.990376353263855),\n",
       " (u'kill', 0.9903687238693237),\n",
       " (u'Israel', 0.9903035163879395),\n",
       " (u'near', 0.9903000593185425),\n",
       " (u'tensions', 0.9902849793434143)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['rank'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'S', 0.9927763938903809),\n",
       " (u'Play', 0.9926636219024658),\n",
       " (u'ROYALTY', 0.9924790859222412),\n",
       " (u'@BrookingsInst', 0.991484522819519),\n",
       " (u'Datastore', 0.9911888241767883),\n",
       " (u'Java', 0.9907231330871582),\n",
       " (u'famous', 0.9905280470848083),\n",
       " (u'miss', 0.9904383420944214),\n",
       " (u'Rank', 0.990268349647522),\n",
       " (u'hide', 0.9891901016235352)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['Google'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'opposition', 0.998782753944397),\n",
       " (u'/', 0.997977614402771),\n",
       " (u'Russia', 0.9974946975708008),\n",
       " (u'must', 0.997404932975769),\n",
       " (u'by', 0.9969280958175659),\n",
       " (u'democractic', 0.9967551231384277),\n",
       " (u'internet', 0.996660053730011),\n",
       " (u'Arab', 0.996646523475647),\n",
       " (u'Ads', 0.9966259002685547),\n",
       " (u'prison', 0.9964969754219055),\n",
       " (u'+', 0.9964832663536072),\n",
       " (u'death', 0.9963929057121277)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['Syria'],topn=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2d\n",
    "\n",
    "Adjust the choices in (b) and (c) as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Filter tweets to those that mention 'Iran' or similar entities and 'plan' or similar entities.\n",
    "* Do this using just spacy.\n",
    "* Do this using word2vec similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using word2vec similarity scores\n",
    "def tweet_sim(word_1,word_2,threshold_1=0.99,threshold_2=0.99):\n",
    "    tweet_list = []\n",
    "    i = 0\n",
    "    for tweet in tweets[:200]:\n",
    "        tweet_sublist = []\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        similarity_to_1 = max([model.similarity(word_1, tok.text) for tok in parsed if tok.text in model.wv.vocab])\n",
    "        similarity_to_2 = max([model.similarity(word_2, tok.text) for tok in parsed if tok.text in model.wv.vocab])\n",
    "        if similarity_to_1 > threshold_1 and similarity_to_2 > threshold_2:\n",
    "            tweet_sublist.append(i)\n",
    "            tweet_sublist.append([similarity_to_1, similarity_to_2])\n",
    "            tweet_sublist.append(tweet)\n",
    "            tweet_list.append(tweet_sublist)\n",
    "            i += 1\n",
    "        \n",
    "    print 'tweets above threshold:', i\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets above threshold: 64\n"
     ]
    }
   ],
   "source": [
    "list_google_find = tweet_sim('Google','find',0.99,0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Claim your Google Play Gift Card Code... https://t.co/ySYH1x5kQl #amazon #itunes #googl\\u2026 https://t.co/ayDI4X1FKO\\n',\n",
       " u\"I've entered to win a Google Nexus 6P from  !    https://t.co/4vFHfhaBey\\n\",\n",
       " u\"RT @kamcb29: I've entered to win a Google Nexus 6P from @MakeUseOf ! https://t.co/o30B9xG6Dx #giveaway #competition\\n\",\n",
       " u'I LOVE your Google plus page with the other girls! \\U0001f49c\\U0001f606\\n',\n",
       " u\"After I've Google &amp; read a ton of articles on the same subject, I remember, I could've just searched YouTube for this shit \\U0001f620\\n\",\n",
       " u'RT @ShowerThoughtts: Apple has \"air\", Amazon has \"Fire\", Google has \"earth\", why doesn\\'t Microsoft have \"water\"?\\n',\n",
       " u\"-Looks up on Google 'MikexJeremy' secretly- &lt;33 ;) [@FnafSchimdt,@MikeSchmit10,]#SenpaiBot~\\n\",\n",
       " u'RT @_silentbent_: Go support @dadeputy single \"It\\'s Okay\" feat @jaesongreen on iTunes,Google\\u2026 https://t.co/WPc1jwFLs0\\n',\n",
       " u'Ever wanted to become a Google Small Business Advisor? Now you can! https://t.co/fcOkq6srSX\\n',\n",
       " u'Top Android Apps (without all the games) revealed in hidden Google Play Store link -\\u2026 https://t.co/7ZSs9MkcLm #Android #India\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lg[2] for lg in list_google_find][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets above threshold: 61\n"
     ]
    }
   ],
   "source": [
    "list_iran_plan = tweet_sim('Iran','plan',0.99,0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"RT @kamcb29: I've entered to win a Google Nexus 6P from @MakeUseOf ! https://t.co/o30B9xG6Dx #giveaway #competition\\n\",\n",
       " u\"After I've Google &amp; read a ton of articles on the same subject, I remember, I could've just searched YouTube for this shit \\U0001f620\\n\",\n",
       " u'RT @ShowerThoughtts: Apple has \"air\", Amazon has \"Fire\", Google has \"earth\", why doesn\\'t Microsoft have \"water\"?\\n',\n",
       " u'RT @_silentbent_: Go support @dadeputy single \"It\\'s Okay\" feat @jaesongreen on iTunes,Google\\u2026 https://t.co/WPc1jwFLs0\\n',\n",
       " u'Check out @GCloudAndroid. Never worry about losing your #Android device up to 10 GB Free to backup https://t.co/7eaqZEHAnI\\n',\n",
       " u'Top Android Apps (without all the games) revealed in hidden Google Play Store link -\\u2026 https://t.co/7ZSs9MkcLm #Android #India\\n',\n",
       " u\"                    Europe could produce a Facebook ' and the Google of healthcare\\n\",\n",
       " u\"                    Europe could produce a Facebook \\\\' and the Google of healthcare\\n\",\n",
       " u'#USA #israel \\n',\n",
       " u'The first time someone commented \"Schwing!\" on one of my selfies, I had to google what it was. It\\'s basically an old guy complimenting you.\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lg[2] for lg in list_iran_plan][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
