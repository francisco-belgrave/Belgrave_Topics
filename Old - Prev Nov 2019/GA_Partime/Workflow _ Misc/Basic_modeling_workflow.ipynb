{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling workflow\n",
    "\n",
    "Even though we cover many different models, the steps that we need to take from getting from raw data to results, its usually very similar. \n",
    "\n",
    "We assume you already have a data set with the features and the target you want to model (this is the output you get from doing the EDA).\n",
    "\n",
    "Basic Workflow:\n",
    "-----\n",
    "\n",
    "1. Do Training/Test split on the dataframe.\n",
    "\n",
    "2. Create an Instance of the model.\n",
    "\n",
    "3. Fit the model with the training data.\n",
    "\n",
    "4. Asses the model we just fitted with the test data.\n",
    "\n",
    "5. (Optional) Use predict to generate new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the libraries that we will need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the Boston Housing dataset, that's included in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "features_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "features_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(boston.target, columns=[\"MEDV\"])\n",
    "target_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "Now that we have the data (features and target), we will go through the steps in the workflow, so we can fit a linear regression on _**all**_ of our features.\n",
    "\n",
    "#### 1: Do Training/Test split on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df, target_df, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Create an Instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Fit the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_regr = regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Asses the model we just fitted with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Variance score: %.2f' % regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: (Optional) Use predict to generate new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this simulates a feature row for a house we want to predict the prices \n",
    "new_sample = np.array([0.00632, 18.0, 2.31, 0.0, 0.538, \n",
    "              6.575, 65.2, 4.0900, 1.0 ,296.0, 15.3, 396.90, 4.98]\n",
    "            ).reshape(1, -1) # this is necessary to mute a warning from sklearn.\n",
    "\n",
    "print \"New house price: \" + str(fitted_regr.predict(new_sample)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More advanced workflows:\n",
    "\n",
    "We have just covered a basic workflow, but there are more things you can add, that might improve your end performance.\n",
    "\n",
    "Things we haven't cover in this notebook: \n",
    "\n",
    "- EDA (specially feature selection and feature engineering)\n",
    "- Hyperparameter optimization with Gridsearch.\n",
    "- Crossvalidation for model assessment.\n",
    "- More advanced model assesment (specially important for classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
