{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "<img src=\"https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_300,w_300,f_auto,q_auto/1266110/Logo_wzxi0f.png\" style=\"float: left; margin: 20px; height: 55px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Day 27 - Exercises Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use `thinkstats2.SampleRows` to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resources.Think_Stats.Thinkstats2 import first\n",
    "from Resources.Think_Stats.Thinkstats2 import thinkstats2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "live, firsts, others = first.MakeFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "    \n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "        \n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationPermute(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        xs, ys = data\n",
    "        test_stat = abs(thinkstats2.Corr(xs, ys))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        xs, ys = self.data\n",
    "        xs = np.random.permutation(xs)\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "        \n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        firsts, others = data\n",
    "        stat = self.ChiSquared(firsts) + self.ChiSquared(others)\n",
    "        return stat\n",
    "    \n",
    "    def ChiSquared(self, lengths):\n",
    "        hist = thinkstats2.Hist(lengths)\n",
    "        observed = np.array(hist.Freqs(self.values))\n",
    "        expected = self.expected_probs * len(lengths)\n",
    "        stat = sum((observed - expected)**2 / expected)\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunTests(live, iters=1000):\n",
    "    \"\"\"Runs the tests from Chapter 9 with a subset of the data.\n",
    "\n",
    "    live: DataFrame\n",
    "    iters: how many iterations to run\n",
    "    \"\"\"\n",
    "    n = len(live)\n",
    "    firsts = live[live.birthord == 1]\n",
    "    others = live[live.birthord != 1]\n",
    "\n",
    "    # compare pregnancy lengths\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p1 = ht.PValue(iters=iters)\n",
    "\n",
    "    data = (firsts.totalwgt_lb.dropna().values,\n",
    "            others.totalwgt_lb.dropna().values)\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p2 = ht.PValue(iters=iters)\n",
    "\n",
    "    # test correlation\n",
    "    live2 = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    data = live2.agepreg.values, live2.totalwgt_lb.values\n",
    "    ht = CorrelationPermute(data)\n",
    "    p3 = ht.PValue(iters=iters)\n",
    "\n",
    "    # compare pregnancy lengths (chi-squared)\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = PregLengthTest(data)\n",
    "    p4 = ht.PValue(iters=iters)\n",
    "\n",
    "    print('%d\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f' % (n, p1, p2, p3, p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9148\t0.15\t0.00\t0.00\t0.00\n",
      "4574\t0.15\t0.00\t0.00\t0.00\n",
      "2287\t0.01\t0.18\t0.02\t0.00\n",
      "1143\t0.61\t0.00\t0.00\t0.00\n",
      "571\t0.08\t0.20\t0.09\t0.01\n",
      "285\t0.55\t0.29\t0.22\t0.05\n",
      "142\t0.60\t0.16\t1.00\t0.64\n"
     ]
    }
   ],
   "source": [
    "n = len(live)\n",
    "for _ in range(7):\n",
    "    sample = thinkstats2.SampleRows(live, n)\n",
    "    RunTests(sample)\n",
    "    n //= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My results:\n",
    "\n",
    "# test1: difference in mean pregnancy length\n",
    "# test2: difference in mean birth weight\n",
    "# test3: correlation of mother's age and birth weight\n",
    "# test4: chi-square test of pregnancy length\n",
    "\n",
    "# n       test1   test2   test2   test4\n",
    "# 9148\t0.16\t0.00\t0.00\t0.00\n",
    "# 4574\t0.10\t0.01\t0.00\t0.00\n",
    "# 2287\t0.25\t0.06\t0.00\t0.00\n",
    "# 1143\t0.24\t0.03\t0.39\t0.03\n",
    "# 571\t0.81\t0.00\t0.04\t0.04\n",
    "# 285\t0.57\t0.41\t0.48\t0.83\n",
    "# 142\t0.45\t0.08\t0.60\t0.04\n",
    "\n",
    "# Conclusion: As expected, tests that are positive with large sample\n",
    "# sizes become negative as we take away data.  But the pattern is\n",
    "# erratic, with some positive tests even at small sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "false"
   },
   "source": [
    "In Section 9.3, we simulated the null hypothesis by permutation; that is, we treated the observed values as if they represented the entire population, and randomly assigned the members of the population to the two groups.\n",
    "\n",
    "An alternative is to use the sample to estimate the distribution for the population, then draw a random sample from that distribution. This process is called resampling. There are several ways to implement resampling, but one of the simplest is to draw a sample with replacement from the observed values, as in Section 9.10.\n",
    "\n",
    "Write a class named `DiffMeansResample` that inherits from `DiffMeansPermute` and overrides `RunModel` to implement resampling, rather than permutation.\n",
    "\n",
    "Use this model to test the differences in pregnancy length and birth weight. How much does the model affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansResample(DiffMeansPermute):\n",
    "    \"\"\"Tests a difference in means using resampling.\"\"\"\n",
    "    \n",
    "    def RunModel(self):\n",
    "        \"\"\"Run the model of the null hypothesis.\n",
    "\n",
    "        returns: simulated data\n",
    "        \"\"\"\n",
    "        group1 = np.random.choice(self.pool, self.n, replace=True)\n",
    "        group2 = np.random.choice(self.pool, self.m, replace=True)\n",
    "        return group1, group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunResampleTest(firsts, others):\n",
    "    \"\"\"Tests differences in means by resampling.\n",
    "\n",
    "    firsts: DataFrame\n",
    "    others: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Permuation')\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p_value = ht.PValue(iters=10000)\n",
    "    print('\\ndiff means permute preglength')\n",
    "    print('p-value =', p_value)\n",
    "    print('actual =', ht.actual)\n",
    "    print('ts max =', ht.MaxTestStat())\n",
    "    \n",
    "    data = (firsts.totalwgt_lb.dropna().values,\n",
    "            others.totalwgt_lb.dropna().values)\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p_value = ht.PValue(iters=10000)\n",
    "    print('\\ndiff means permute birthweight')\n",
    "    print('p-value =', p_value)\n",
    "    print('actual =', ht.actual)\n",
    "    print('ts max =', ht.MaxTestStat())\n",
    "    \n",
    "    print('\\nResample')\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = DiffMeansResample(data)\n",
    "    p_value = ht.PValue(iters=10000)\n",
    "    print('\\ndiff means resample preglength')\n",
    "    print('p-value =', p_value)\n",
    "    print('actual =', ht.actual)\n",
    "    print('ts max =', ht.MaxTestStat())\n",
    "\n",
    "    data = (firsts.totalwgt_lb.dropna().values,\n",
    "            others.totalwgt_lb.dropna().values)\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p_value = ht.PValue(iters=10000)\n",
    "    print('\\ndiff means resample birthweight')\n",
    "    print('p-value =', p_value)\n",
    "    print('actual =', ht.actual)\n",
    "    print('ts max =', ht.MaxTestStat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuation\n",
      "\n",
      "diff means permute preglength\n",
      "p-value = 0.1621\n",
      "actual = 0.07803726677754952\n",
      "ts max = 0.21769433738419508\n",
      "\n",
      "diff means permute birthweight\n",
      "p-value = 0.0\n",
      "actual = 0.12476118453549034\n",
      "ts max = 0.1089483944349725\n",
      "\n",
      "Resample\n",
      "\n",
      "diff means resample preglength\n",
      "p-value = 0.1641\n",
      "actual = 0.07803726677754952\n",
      "ts max = 0.21297333332375956\n",
      "\n",
      "diff means resample birthweight\n",
      "p-value = 0.0\n",
      "actual = 0.12476118453549034\n",
      "ts max = 0.11468105030022802\n"
     ]
    }
   ],
   "source": [
    "RunResampleTest(firsts, others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusions: Using resampling instead of permutation has very\n",
    "# little effect on the results.\n",
    "\n",
    "# The two models are based on slightly difference assumptions, and in\n",
    "# this example there is no compelling reason to choose one or the other.\n",
    "# But in general p-values depend on the choice of the null hypothesis;\n",
    "# different models can yield very different results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
