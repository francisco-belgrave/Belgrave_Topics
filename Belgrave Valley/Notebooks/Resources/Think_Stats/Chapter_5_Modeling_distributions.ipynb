{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Modeling distributions\n",
    "\n",
    "The distributions we have used so far are called **empirical distributions** because they are based on empirical observations, which are necessarily finite samples.\n",
    "\n",
    "The alternative is an **analytic distribution**, which is characterized by a CDF that is a mathematical function. Analytic distributions can be used to model empirical distributions. In this context, a model is a simplification\n",
    "that leaves out unneeded details. This chapter presents common analytic distributions and uses them to model data from a variety of sources.\n",
    "\n",
    "## The exponential distribution\n",
    "\n",
    "I’ll start with the exponential distribution because it is relatively simple.The CDF of the exponential distribution is:\n",
    "\n",
    "![alt text](notebookpics/exponential_formula.png \"Title\")\n",
    "\n",
    "The parameter, λ, determines the shape of the distribution.\n",
    "\n",
    "Draw and compare the distribution for the values of the λ = 0.5, 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Thinkstats2 import analytic\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world, exponential distributions come up when we look at a series of events and measure the times between events, called interarrival times. If the events are equally likely to occur at any time, the distribution of **interarrival times** tends to look like an exponential distribution.\n",
    "\n",
    "As an example, we will look at the interarrival time of births. On December 18, 1997, 44 babies were born in a hospital in Brisbane, Australia. The time of birth for all 44 babies was reported in the local paper; the complete dataset is in a file called `babyboom.dat`, in the `ThinkStats2` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analytic.ReadBabyBoom(filename='Thinkstats2/babyboom.dat')\n",
    "diffs = df.minutes.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReadBabyBoom` reads the data file and returns a DataFrame with columns `time`, `sex`, `weight_g`, and `minutes`, where minutes is time of birth converted to minutes since midnight.\n",
    "\n",
    "`diffs` is the difference between consecutive birth times, and `cdf` is the distribution of these interarrival times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the CDF of the diff distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it with the result of the `thinkstas2` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the CDF. It seems to have the general shape of an exponential distribution, but how can we\n",
    "tell?\n",
    "\n",
    "One way is to plot the **complementary CDF**, which is 1 − CDF(x), on a log-y scale. For data from an exponential distribution, the result is a straight line. Let’s see why that works.\n",
    "\n",
    "If you plot the complementary CDF (CCDF) of a dataset that you think is exponential, you expect to see a function like:\n",
    "\n",
    "![alt text](notebookpics/complementary_exponential.png \"Title\")\n",
    "\n",
    "Taking the log of both sides yields:\n",
    "\n",
    "![alt text](notebookpics/complementary_exp.png \"Title\")\n",
    "\n",
    "So on a log-y scale the CCDF is a straight line with slope −λ. knowing that the complementary is 1 - x would you be able to plot the complementary CDF of the interrarival times? (remember that your y axis need to be in logarithmic scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following code will probably be useful\n",
    "xs, ps = cdf.Render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here’s how we can generate a plot like that with `thinkstats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "thinkplot.Cdf(cdf, complement=True)\n",
    "thinkplot.Show(xlabel='minutes',\n",
    "               ylabel='CCDF',\n",
    "               yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the argument `complement=True`, `thinkplot.Cdf` computes the complementary CDF before plotting. And with `scale=’log’`, `thinkplot.Show` sets the y axis to a logarithmic scale.\n",
    "\n",
    "The result is not exactly straight, which indicates that the exponential distribution is not a perfect model for this data. Most likely the underlying assumption —that a birth is equally likely at any time of day— is not exactly true. Nevertheless, it might be reasonable to model this dataset with an exponential distribution. With that simplification, we can summarize the distribution with a single parameter.\n",
    "\n",
    "**The parameter, λ, can be interpreted as a rate; that is, the number of events that occur, on average, in a unit of time.** In this example, 44 babies are born in 24 hours, so the rate is λ = 0.0306 births per minute. The mean of an exponential distribution is 1/λ, so the mean time between births is 32.7 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal distribution\n",
    "\n",
    "The normal distribution, also called Gaussian, is commonly used because it describes many phenomena, at least approximately. It turns out that there is a good reason for its ubiquity, which we will get to in chapter 14.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean, μ, and standard deviation σ. The normal distribution with μ = 0 and σ = 1 is called the standard normal distribution. Its CDF is defined by an integral that does not have a closed form solution, but there are algorithms that evaluate it efficiently. One of them is provided by SciPy: scipy.stats.norm is an object that represents a normal distribution; it provides a method, cdf, that evaluates the standard normal CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.norm.cdf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is correct: the median of the standard normal distribution is 0 (the same as the mean), and half of the values fall below the median, so CDF(0) is 0.5.\n",
    "\n",
    "`norm.cdf` takes optional parameters: `loc`, which specifies the mean, and `scale`, which specifies the standard deviation.\n",
    "\n",
    "Try to calculate and plot with `scipy.stats.norm` the distributions with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = [1.0, 2.0, 3.0]\n",
    "sigmas = [0.5, 0.4, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`thinkstats2` makes this function a little easier to use by providing `RenderNormalCdf`, which takes parameters mu and sigma and evaluates the CDF at x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "thinkplot.PrePlot(3)\n",
    "\n",
    "mus = [1.0, 2.0, 3.0]\n",
    "sigmas = [0.5, 0.4, 0.3]\n",
    "for mu, sigma in zip(mus, sigmas):\n",
    "    xs, ps = thinkstats2.RenderNormalCdf(mu=mu, sigma=sigma, \n",
    "                                               low=-1.0, high=4.0)\n",
    "    label = r'$\\mu=%g$, $\\sigma=%g$' % (mu, sigma)\n",
    "    thinkplot.Plot(xs, ps, label=label)\n",
    "\n",
    "thinkplot.Config(title='Normal CDF', xlabel='x', ylabel='CDF',\n",
    "                 loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter we looked at the distribution of birth weights in the `NSFG`. Plot again the CDF of this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nsfg\n",
    "\n",
    "preg = nsfg.ReadFemPreg(dct_file='../Think_Stats/Thinkstats2/2002FemPreg.dct',\n",
    "                      dat_file='Thinkstats2/2002FemPreg.dat.gz',\n",
    "                       clean = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate now the mean and standart deviation of this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on this mean and standart deviation statistis create the CDF of the normal distribution defined by those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot together both CDFs and comment the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first chart shows the empirical CDF of weights for all live births and the CDF of a normal distribution with the same mean and variance.\n",
    "\n",
    "The normal distribution is a good model for this dataset, so if we summarize the distribution with the parameters μ = 7.28 and σ = 1.24, the resulting error (difference between the model and the data) is small.\n",
    "\n",
    "Below the 10th percentile there is a discrepancy between the data and the model; there are more light babies than we would expect in a normal distribution. If we are specifically interested in preterm babies, it would be important to get this part of the distribution right, so it might not be appropriate to use the normal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal probability plot\n",
    "\n",
    "For the exponential distribution, and a few others, there are simple transformations we can use to test whether an analytic distribution is a good model for a dataset.\n",
    "\n",
    "For the normal distribution there is no such transformation, but there is an alternative called a normal probability plot. There are two ways to generate a normal probability plot: the hard way and the easy way. If you are interested in the hard way, you can read about it at https://en.wikipedia.org/wiki/Normal_probability_plot. Here’s the easy way:\n",
    "\n",
    "1. Sort the values in the sample.\n",
    "2. From a standard normal distribution (μ = 0 and σ = 1), generate a random sample with the same size as the sample, and sort it.\n",
    "3. Plot the sorted values from the sample versus the random values.\n",
    "\n",
    "If the distribution of the sample is approximately normal, the result is a straight line with intercept mu and slope sigma. `thinkstats2` provides `NormalProbability`, which takes a sample and returns two `NumPy` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test `NormalProbability` I generated some fake samples that were actually drawn from normal distributions with various parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.normal(mu, sigma, n)\n",
    "xs, ys = thinkstats2.NormalProbability(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ys` contains the sorted values from sample; `xs` contains the random values from the standard normal distribution.\n",
    "\n",
    "Create a grahp line of the values created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s try it with real data. Code to generate a normal probability plot for the birth weight data from the previous section. It plots a gray line that represents the model and a blue line that represents the data. Show the results for all live births, and also for full term births."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both curves match the model near the mean and deviate in the tails. The heaviest babies are heavier than\n",
    "what the model expects, and the lightest babies are lighter.\n",
    "\n",
    "When we select only full term births, we remove some of the lightest weights, which reduces the discrepancy in the lower tail of the distribution.\n",
    "\n",
    "This plot suggests that the normal model describes the distribution well within a few standard deviations from the mean, but not in the tails. Whether it is good enough for practical purposes depends on the purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The lognormal distribution\n",
    "\n",
    "If the logarithms of a set of values have a normal distribution, the values have a **lognormal distribution**. The CDF of the lognormal distribution is the same as the CDF of the normal distribution, with log x substituted for x.\n",
    "\n",
    "![alt text](notebookpics/lognormal.png \"Title\")\n",
    "\n",
    "The parameters of the lognormal distribution are usually denoted μ and σ. But remember that these parameters are not the mean and standard deviation; the mean of a lognormal distribution is exp(μ + σ 2 /2) and the standard deviation is ugly (see http://wikipedia.org/wiki/Log-normal_distribution).\n",
    "\n",
    "If a sample is approximately lognormal and you plot its CDF on a log-x scale, it will have the characteristic shape of a normal distribution. To test how well the sample fits a lognormal model, you can make a normal probability plot using the log of the values in the sample.\n",
    "\n",
    "The National Center for Chronic Disease Prevention and Health Promotion conducts an annual survey as part of the Behavioral Risk Factor Surveillance System (BRFSS). 3 In 2008, they interviewed 414,509 respondents and asked about their demographics, health, and health risks. Among the data they collected are the weights in kilograms of 398,484 respondents.\n",
    "\n",
    "The repository for this book contains `CDBRFS08.ASC.gz`, a fixed-width ASCII file that contains data from the `BRFSS`, and `brfss.py`, which reads the file and analyzes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Thinkstats2 import brfss\n",
    "df = brfss.ReadBrfss(filename='Thinkstats2/CDBRFS08.ASC.gz')\n",
    "weights = df.wtkg2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cdf of the weights and follow the steps on the previous chapter to test whether the variable weight is distributed normally.\n",
    "\n",
    "Start by ploting the cdf of the variable and its comparative estimation with the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the comparison with the random sampling of observations, just like we did before, to check whether the variable follows a normal distribution itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same test using the log of the weights.\n",
    "\n",
    "Start by ploting the cdf of the variable and its comparative estimation with the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_weights = np.log10(weights)\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the comparison with the random sampling of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The normal distribution graph shows the distribution of adult weights on a linear scale with a normal model. The logscale distribution shows the same distribution on a log scale with a lognormal model. The lognormal model is a better fit, but this representation of the data does not make the difference particularly dramatic.\n",
    "\n",
    "In the comparison of the random sampling it is apparent that the data deviate substantially from the normal model. On the other hand, the lognormal model is a good match for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pareto distribution\n",
    "\n",
    "The Pareto distribution is named after the economist Vilfredo Pareto, who used it to describe the distribution of wealth (see http://wikipedia.org/wiki/Pareto_distribution). Since then, it has been used to describe phenomena in the natural and social sciences including sizes of cities and towns, sand particles and meteorites, forest fires and earthquakes.\n",
    "\n",
    "The CDF of the Pareto distribution is:\n",
    "\n",
    "![alt text](notebookpics/pareto_dist.png \"Title\")\n",
    "\n",
    "The parameters x m and α determine the location and shape of the distribution. x m is the minimum possible value.\n",
    "\n",
    "Based on the formula plot a pareto distribution xm = 0.5 and α = 1,2,0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a simple visual test that indicates whether an empirical distribution fits a Pareto distribution: on a log-log scale, the CCDF looks like a straight line. Let’s see why that works. If you plot the CCDF of a sample from a Pareto distribution on a linear scale, you expect to see a function like:\n",
    "![alt text](notebookpics/pareto_transformation.png \"Title\")\n",
    "So if you plot log y versus log x, it should look like a straight line with slope −α and intercept α log x m .\n",
    "\n",
    "As an example, let’s look at the sizes of cities and towns. The U.S. Census Bureau publishes the population of every incorporated city and town in the United States.\n",
    "\n",
    "Download their data from http://www.census.gov/popest/data/cities/totals/2012/SUB-EST2012-3.html; it is in the repository for this book in a file named `PEP_2012_PEPANNRES_with_ann.csv`. The repository also contains `populations.py`, which reads the file (`ReadData()`) and plots the distribution of populations (`MakeFigure()`, ).\n",
    "\n",
    "Create a plot of the population on a log-log scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Thinkstats2 import populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest 1% of cities and towns, below 10 −2 , fall along a straight line. So we could conclude, as some researchers have, that the tail of this distribution fits a Pareto model.\n",
    "\n",
    "Now plot and also compare the CDF with a lognormal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither model is perfect. The Pareto model only applies to the largest 1% of cities, but it is a better fit for that part of the distribution. The lognormal model is a better fit for the other 99%. Which model is appropriate depends on which part of the distribution is relevant.\n",
    "\n",
    "## Generating Random Numbers\n",
    "\n",
    "Analytic CDFs can be used to generate random numbers with a given distribution function, p = CDF(x). If there is an efficient way to compute the inverse CDF, we can generate random values with the appropriate distribution by choosing p from a uniform distribution between 0 and 1, then choosing x = ICDF (p).\n",
    "\n",
    "For example, the CDF of the exponential distribution is:\n",
    "\n",
    "![alt text](notebookpics/random_exp.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expovariate(lam):\n",
    "    p = random.random()\n",
    "    x = -np.log(1-p) / lam\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test it by generating a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [expovariate(lam=2) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plotting the CCDF on a log-y scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = thinkstats2.Cdf(t)\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "thinkplot.Cdf(cdf, complement=True)\n",
    "thinkplot.Config(xlabel='Exponential variate', ylabel='CCDF', yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straight line is consistent with an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As an exercise, write a function that generates a Pareto variate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why model?\n",
    "\n",
    "At the beginning of this chapter, I said that many real world phenomena can be modeled with analytic distributions. “So,” you might ask, “what?”\n",
    "\n",
    "Like all models, analytic distributions are abstractions, which means they leave out details that are considered irrelevant. For example, an observed distribution might have measurement errors or quirks that are specific to the\n",
    "sample; analytic models smooth out these idiosyncrasies.\n",
    "\n",
    "Analytic models are also a form of data compression. When a model fits a dataset well, a small set of parameters can summarize a large amount of data.\n",
    "\n",
    "It is sometimes surprising when data from a natural phenomenon fit an analytic distribution, but these observations can provide insight into physical systems. Sometimes we can explain why an observed distribution has a particular form. For example, Pareto distributions are often the result of generative processes with positive feedback (so-called preferential attachment processes: see http://wikipedia.org/wiki/Preferential_attachment.).\n",
    "\n",
    "Also, analytic distributions lend themselves to mathematical analysis, as we will see in Chapter 14.\n",
    "\n",
    "But it is important to remember that all models are imperfect. Data from the real world never fit an analytic distribution perfectly. People sometimes talk as if data are generated by models; for example, they might say that\n",
    "the distribution of human heights is normal, or the distribution of income is lognormal. Taken literally, these claims cannot be true; there are always differences between the real world and mathematical models.\n",
    "\n",
    "Models are useful if they capture the relevant aspects of the real world and leave out unneeded details. But what is “relevant” or “unneeded” depends on what you are planning to use the model for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "In the BRFSS (see Section 5.4), the distribution of heights is roughly normal with parameters µ = 178 cm and σ = 7.7 cm for men, and µ = 163 cm and σ = 7.3 cm for women.\n",
    "\n",
    "In order to join Blue Man Group, you have to be male between 5’10” and 6’1” (see http://bluemancasting.com). What percentage of the U.S. male population is in this range? Hint: use `scipy.stats.norm.cdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.stats` contains objects that represent analytic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example <tt>scipy.stats.norm</tt> represents a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 178\n",
    "sigma = 7.7\n",
    "dist = scipy.stats.norm(loc=mu, scale=sigma)\n",
    "type(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"frozen random variable\" can compute its mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.mean(), dist.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also evaluate its CDF.  How many people are more than one standard deviation below the mean?  About 16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.cdf(mu-sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people are between 5'10\" and 6'1\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\n",
    "To get a feel for the Pareto distribution, let’s see how different the world would be if the distribution of human height were Pareto. With the parameters xm = 1 m and α = 1.7, we get a distribution with a reasonable minimum, 1 m, and median, 1.5 m.\n",
    "\n",
    "Plot this distribution. What is the mean human height in Pareto world? What fraction of the population is shorter than the mean? If there are 7 billion people in Pareto world, how many do we expect to be taller than 1 km? How tall do we expect the tallest person to be?\n",
    "\n",
    "`scipy.stats.pareto` represents a pareto distribution.  In Pareto world, the distribution of human heights has parameters alpha=1.7 and xmin=1 meter.  So the shortest person is 100 cm and the median is 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.7\n",
    "xmin = 1       # meter\n",
    "dist = scipy.stats.pareto(b=alpha, scale=xmin)\n",
    "dist.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the mean height in Pareto world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fraction of people are shorter than the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 7 billion people, how many do we expect to be taller than 1 km?  You could use <tt>dist.cdf</tt> or <tt>dist.sf</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How tall do we expect the tallest person to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)\n",
    "The Weibull distribution is a generalization of the exponential distribution that comes up in failure analysis (see http://wikipedia.org/wiki/Weibull_distribution). Its CDF is\n",
    "\n",
    "$\\mathrm{CDF}(x) = 1 − \\exp[−(x / λ)^k]$ \n",
    "\n",
    "Can you find a transformation that makes a Weibull distribution look like a straight line? What do the slope and intercept of the line indicate?\n",
    "\n",
    "Use `random.weibullvariate` to generate a sample from a Weibull distribution and use it to test your transformation.\n",
    "\n",
    "Generate a sample from a Weibull distribution and plot it using a transform that makes a Weibull distribution look like a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`thinkplot.Cdf` provides a transform that makes the CDF of a Weibull distribution look like a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [random.weibullvariate(2, 1) for _ in range(1000)]\n",
    "cdf = thinkstats2.Cdf(sample)\n",
    "thinkplot.Cdf(cdf, transform='weibull')\n",
    "thinkplot.Config(xlabel='Weibull variate', ylabel='CCDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\n",
    "For small values of `n`, we don’t expect an empirical distribution to fit an analytic distribution exactly. One way to evaluate the quality of fit is to generate a sample from an analytic distribution and see how well it matches the data.\n",
    "\n",
    "For example, in Section 5.1 we plotted the distribution of time between births and saw that it is approximately exponential. But the distribution is based on only 44 data points. To see whether the data might have come from an exponential distribution, generate 44 values from an exponential distribution with the same mean as the data, about 33 minutes between births.\n",
    "\n",
    "Plot the distribution of the random values and compare it to the actual distribution. You can use random.expovariate to generate the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analytic\n",
    "\n",
    "df = analytic.ReadBabyBoom()\n",
    "diffs = df.minutes.diff()\n",
    "cdf = thinkstats2.Cdf(diffs, label='actual')\n",
    "\n",
    "n = len(diffs)\n",
    "lam = 44.0 / 24 / 60\n",
    "sample = [random.expovariate(lam) for _ in range(n)]\n",
    "\n",
    "1/lam, np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "In the repository for this book, you’ll find a set of data files called mystery0.dat, mystery1.dat, and so on. Each contains a sequence of random numbers generated from an analytic distribution.\n",
    "\n",
    "You will also find test_models.py, a script that reads data from a file and plots the CDF under a variety of transforms. You can run it like this:\n",
    "    \n",
    "    $ python3 test_models.py mystery0.dat\n",
    "    \n",
    "Based on these plots, you should be able to infer what kind of distribution generated each file. If you are stumped, you can look in mystery.py, which contains the code that generated the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)\n",
    "The distributions of wealth and income are sometimes modeled using lognormal and Pareto distributions. To see which is better, let’s look at some data.\n",
    "\n",
    "The Current Population Survey (CPS) is a joint effort of the Bureau of Labor Statistics and the Census Bureau to study income and related variables. Data collected in 2013 is available from http://www.census.gov/hhes/www/cpstables/032013/hhinc/toc.htm. I downloaded hinc06.xls, which is an\n",
    "Excel spreadsheet with information about household income, and converted it to hinc06.csv, a CSV file you will find in the repository for this book. You will also find hinc.py, which reads this file. \n",
    "\n",
    "Extract the distribution of incomes from this dataset. Are any of the analytic distributions in this chapter a good model of the data? A solution to this exercise is in hinc_soln.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Worked Example:** The distributions of wealth and income are sometimes modeled using lognormal and Pareto distributions. To see which is better, let’s look at some data.\n",
    "\n",
    "The Current Population Survey (CPS) is a joint effort of the Bureau of Labor Statistics and the Census Bureau to study income and related variables. Data collected in 2013 is available from http://www.census.gov/hhes/www/cpstables/032013/hhinc/toc.htm. I downloaded `hinc06.xls`, which is an Excel spreadsheet with information about household income, and converted it to `hinc06.csv`, a CSV file you will find in the repository for this book. You will also find `hinc.py`, which reads this file.\n",
    "\n",
    "Extract the distribution of incomes from this dataset. Are any of the analytic distributions in this chapter a good model of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hinc\n",
    "df = hinc.ReadData()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the CDF looks like on a linear scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ps = df.income.values, df.ps.values\n",
    "cdf = thinkstats2.Cdf(xs, ps, label='data')\n",
    "cdf_log = thinkstats2.Cdf(np.log10(xs), ps, label='data')\n",
    "    \n",
    "# linear plot\n",
    "thinkplot.Cdf(cdf) \n",
    "thinkplot.Config(xlabel='household income',\n",
    "                   ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether a Pareto model describes the data well, I plot the CCDF on a log-log scale.\n",
    "\n",
    "I found parameters for the Pareto model that match the tail of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = thinkstats2.RenderParetoCdf(xmin=55000, alpha=2.5, \n",
    "                                     low=0, high=250000)\n",
    "\n",
    "thinkplot.Plot(xs, 1-ys, label='model', color='0.8')\n",
    "\n",
    "thinkplot.Cdf(cdf, complement=True) \n",
    "thinkplot.Config(xlabel='log10 household income',\n",
    "                 ylabel='CCDF',\n",
    "                 xscale='log',\n",
    "                 yscale='log', \n",
    "                 loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lognormal model I estimate mu and sigma using percentile-based statistics (median and IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cdf_log.Percentile(50)\n",
    "iqr = cdf_log.Percentile(75) - cdf_log.Percentile(25)\n",
    "std = iqr / 1.349\n",
    "\n",
    "# choose std to match the upper tail\n",
    "std = 0.35\n",
    "print(median, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the distribution, and fitted model, look like on a log-x scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ps = thinkstats2.RenderNormalCdf(median, std, low=3.5, high=5.5)\n",
    "thinkplot.Plot(xs, ps, label='model', color='0.8')\n",
    "\n",
    "thinkplot.Cdf(cdf_log) \n",
    "thinkplot.Config(xlabel='log10 household income',\n",
    "                 ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My conclusions based on these figures are:\n",
    "\n",
    "1) The Pareto model might be a reasonable choice for the top\n",
    "   10-20% of incomes.\n",
    "\n",
    "2) The lognormal model captures the shape of the distribution better,\n",
    "   with some deviation in the left tail.  With different\n",
    "   choices for sigma, you could match the upper or lower tail, but not\n",
    "   both at the same time.\n",
    " \n",
    "In summary I would say that neither model captures the whole distribution,\n",
    "so you might have to \n",
    "\n",
    "1) look for another analytic model, \n",
    "\n",
    "2) choose one that captures the part of the distribution that is most \n",
    "   relevent, or \n",
    "\n",
    "3) avoid using an analytic model altogether."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
