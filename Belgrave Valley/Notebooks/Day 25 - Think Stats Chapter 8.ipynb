{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img src=\"https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_300,w_300,f_auto,q_auto/1266110/Logo_wzxi0f.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "**Still round the corner there may wait, a new road or a secret gate - J.R.R. Tolkien**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Chapter 8: Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## The estimation game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let’s play a game. I think of a distribution, and you have to guess what it is. I’ll give you two hints: it’s a normal distribution, and here’s a random sample drawn from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dist1 = [-0.441, 1.774, -0.101, -1.138, 2.975, -2.138]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What do you think is the mean parameter, μ, of this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "One choice is to use the sample mean, x̄, as an estimate of μ. In this example, x̄ is 0.155, so it would be reasonable to guess μ = 0.155. This process is called **estimation**, and the statistic we used (the sample mean) is called an **estimator**.\n",
    "\n",
    "Using the sample mean to estimate μ is so obvious that it is hard to imagine a reasonable alternative. But suppose we change the game by introducing outliers.\n",
    "\n",
    "I’m thinking of a distribution. It’s a normal distribution, and here’s a sample that was collected by an unreliable surveyor who occasionally puts the decimal point in the wrong place.\n",
    "\n",
    "Calculate the sample mean, x̄ of the following distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dist2 = [-0.441, 1.774, -0.101, -1.138, 2.975, -213.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now what’s your estimate of x̄? Is that the best choice? What are the alternatives you can think of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "One option is to identify and discard outliers, then compute the sample mean of the rest. \n",
    "Another option is to use the median as an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Which estimator is best depends on the circumstances (for example, whether there are outliers) and on what the goal is. Are you trying to minimize errors, or maximize your chance of getting the right answer?\n",
    "\n",
    "If there are no outliers, the sample mean minimizes the **mean squared error (MSE)**. That is, if we play the game many times, and each time compute the error x̄ − μ, the sample mean minimizes\n",
    "\n",
    "![alt text](Think_Stats/notebookpics/mse.png \"Title\")\n",
    "\n",
    "Where m is the number of times you play the estimation game, not to be confused with n, which is the size of the sample used to compute x̄.\n",
    "\n",
    "Create a function that calculates the MSE (mean squared error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def mse():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Apply it to 1000 random distributions of 7 values with `mu = 0` and `sigma = 1` for the estimators mean and median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Which estimator is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Minimizing MSE is a nice property, but it’s not always the best strategy. For example, suppose we are estimating the distribution of wind speeds at a building site. If the estimate is too high, we might overbuild the structure,\n",
    "increasing its cost. But if it’s too low, the building might collapse. Because cost as a function of error is not symmetric, minimizing MSE is not the best strategy.\n",
    "\n",
    "As another example, suppose I roll three six-sided dice and ask you to predict the total. If you get it exactly right, you get a prize; otherwise you get nothing. What would estimator would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In this case the value that minimizes MSE is 10.5, but that would be a bad guess, because the total of three dice is never 10.5. For this game, you want an estimator that has the highest chance of being right, which is a **maximum likelihood estimator (MLE)**. If you pick 10 or 11, your chance of winning is 1 in 8, and that’s the best you can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Guess the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "I’m thinking of a distribution. It’s a normal distribution, and here’s a (familiar) sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dist1 = [-0.441, 1.774, -0.101, -1.138, 2.975, -2.138]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What do you think is the variance, `S^2` , of my distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For large samples, `S^2` is an adequate estimator, but for small samples it tends to be too low. Because of this unfortunate property, it is called a **biased estimator**. An estimator is **unbiased** if the expected total (or mean) error, after many iterations of the estimation game, is 0.\n",
    "\n",
    "Fortunately, there is another simple statistic that is an unbiased estimator of `S^2` :\n",
    "\n",
    "![alt text](Think_Stats/notebookpics/unbiased_var.png \"Title\")\n",
    "\n",
    "For an explanation of why `S^2` is biased, and a proof that `Sn−1` see http://wikipedia.org/wiki/Bias_of_an_estimator .(Homework)\n",
    "\n",
    "The biggest problem with this estimator is that its name and symbol are used inconsistently. The name “sample variance” can refer to either `S^2` or `S^2n-1`, and the symbol `S^2` is used for either or both.\n",
    "\n",
    "Create a function that calculates `S^2n-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def varcorr():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "compare its MSE to the `S^2` on the for 1000 random distributions of 7 values with `mu = 0` and `sigma = 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Properties like MSE and bias are long-term expectations based on many iterations of the estimation game. By running simulations like the ones in this chapter, we can compare estimators and check whether they have desired properties.\n",
    "\n",
    "But when you apply an estimator to real data, you just get one estimate. It would not be meaningful to say that the estimate is unbiased; being unbiased is a property of the estimator, not the estimate.\n",
    "\n",
    "After you choose an estimator with appropriate properties, and use it to generate an estimate, the next step is to characterize the uncertainty of the estimate, which is the topic of the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Sampling distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose you are a scientist studying gorillas in a wildlife preserve. You want to know the average weight of the adult female gorillas in the preserve. To weigh them, you have to tranquilize them, which is dangerous, expensive, and possibly harmful to the gorillas. But if it is important to obtain this information, it might be acceptable to weigh a sample of 9 gorillas. Let’s assume that the population of the preserve is well known, so we can choose a representative sample of adult females. We could use the sample mean, x̄, to estimate the unknown population mean, μ.\n",
    "\n",
    "Having weighed 9 female gorillas, you might find x̄ = 90 kg and sample standard deviation, S = 7.5 kg. The sample mean is an unbiased estimator of μ, and in the long run it minimizes MSE. So if you report a single estimate that summarizes the results, you would report 90 kg.\n",
    "\n",
    "But how confident should you be in this estimate? If you only weigh n = 9 gorillas out of a much larger population, you might be unlucky and choose the 9 heaviest gorillas (or the 9 lightest ones) just by chance. Variation in the estimate caused by random selection is called **sampling error**.\n",
    "\n",
    "To quantify sampling error, we can simulate the sampling process with hypothetical values of μ and σ, and see how much x̄ varies.\n",
    "\n",
    "Since we don’t know the actual values of μ and σ in the population, we’ll use the estimates x̄ and S. So the question we answer is: “If the actual values of μ and σ were 90 kg and 7.5 kg, and we ran the same experiment many\n",
    "times, how much would the estimated mean, x̄, vary?”\n",
    "\n",
    "Run the experiment 1000 times of creating a random distribution of `mu=90`, `sigma=7.5`, `n=9`.  And calculate the means and variances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Plot the Cdf of the means distribution. This is called **sampling distribution** of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import thinkplot\n",
    "import thinkstats2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The mean of the sampling distribution is pretty close to the hypothetical value of μ, which means that the experiment yields the right answer, on average. After 1000 tries, the lowest result is 82 kg, and the highest is 98 kg. This range suggests that the estimate might be off by as much as 8 kg.\n",
    "\n",
    "There are two common ways to summarize the sampling distribution:\n",
    "\n",
    "- **Standard error (SE)** is a measure of how far we expect the estimate to be off, on average. For each simulated experiment, we compute the error, x̄ − μ, and then compute the root mean squared error (RMSE). In this example, it is roughly 2.5 kg.\n",
    "\n",
    "- A **confidence interval (CI)** is a range that includes a given fraction of the sampling distribution. For example, the 90% confidence interval is the range from the 5th to the 95th percentile. In this example, the 90% CI is (86, 94) kg.\n",
    "\n",
    "Repeat the simullations before calculating this two statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Standard errors and confidence intervals are the source of much confusion:\n",
    "\n",
    "- People often confuse standard error and standard deviation. Remember that standard deviation describes variability in a measured quantity; in this example, the standard deviation of gorilla weight is 7.5 kg. Standard error describes variability in an estimate. In this example, the standard error of the mean, based on a sample of 9 measurements, is 2.5 kg. One way to remember the difference is that, as sample size increases, standard error gets smaller; standard deviation does not.\n",
    "\n",
    "- People often think that there is a 90% probability that the actual parameter, μ, falls in the 90% confidence interval. Sadly, that is not true. If you want to make a claim like that, you have to use Bayesian methods (see the book, Think Bayes). The sampling distribution answers a different question: it gives you a sense of how reliable an estimate is by telling you how much it would vary if you ran the experiment again.\n",
    "\n",
    "It is important to remember that confidence intervals and standard errors only quantify sampling error; that is, error due to measuring only part of the population. The sampling distribution does not account for other sources of\n",
    "error, notably sampling bias and measurement error, which are the topics of the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Sampling bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose that instead of the weight of gorillas in a nature preserve, you want to know the average weight of women in the city where you live. It is unlikely that you would be allowed to choose a representative sample of women and\n",
    "weigh them.\n",
    "\n",
    "A simple alternative would be “telephone sampling;” that is, you could choose random numbers from the phone book, call and ask to speak to an adult woman, and ask how much she weighs.\n",
    "\n",
    "Telephone sampling has obvious limitations. For example, the sample is limited to people whose telephone numbers are listed, so it eliminates people without phones (who might be poorer than average) and people with unlisted numbers (who might be richer). Also, if you call home telephones during the day, you are less likely to sample people with jobs. And if you only sample the person who answers the phone, you are less likely to sample people who\n",
    "share a phone line.\n",
    "\n",
    "If factors like income, employment, and household size are related to weight and it is plausible that they are—the results of your survey would be affected one way or another. This problem is called **sampling bias** because it is a property of the sampling process.\n",
    "\n",
    "This sampling process is also vulnerable to self-selection, which is a kind of sampling bias. Some people will refuse to answer the question, and if the tendency to refuse is related to weight, that would affect the results. Finally, if you ask people how much they weigh, rather than weighing them, the results might not be accurate. Even helpful respondents might round up or down if they are uncomfortable with their actual weight. And not all respondents are helpful. These inaccuracies are examples of **measurement error**.\n",
    "\n",
    "When you report an estimated quantity, it is useful to report standard error, or a confidence interval, or both, in order to quantify sampling error. But it is also important to remember that sampling error is only one source of error, and often it is not the biggest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Exponential distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let’s play one more round of the estimation game. I’m thinking of a distriution. It’s an exponential distribution, and here’s a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dist3 = [5.384, 4.493, 19.198, 2.790, 6.122, 12.844]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What do you think is the parameter, λ, of this distribution? (hint: search the mean how the mean value of a exponential distribution is calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In general, the mean of an exponential distribution is 1/λ, so working backwards, we might choose L = 1/x̄.\n",
    "\n",
    "L is an estimator of λ. And not just any estimator; it is also the maximum likelihood estimator ([see](http://wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood)). So if you want to maximize your chance of guessing λ exactly, L is the way to go.\n",
    "\n",
    "But we know that x̄ is not robust in the presence of outliers, so we expect L to have the same problem.\n",
    "\n",
    "We can choose an alternative based on the sample median. The median of an exponential distribution is ln(2)/λ, so working backwards again, we can define an estimator\n",
    "\n",
    "![alt text](Think_Stats/notebookpics/lm-estimator.png \"Title\")\n",
    "\n",
    "where m is the sample median.\n",
    "\n",
    "Test the performance of this estimators with a simulation of a 1000 sampling process of `λ=2` with 7 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mydir = os.getcwd() # would be the same path as a.py\n",
    "mydir_new = os.chdir(mydir+\"/Thinkstats2\")\n",
    "from estimation import RMSE, MeanError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What results do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
